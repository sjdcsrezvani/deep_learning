{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a98cfa-f30b-4ae5-a915-195ec06fa4be",
   "metadata": {},
   "source": [
    "first we have to change to text into numbers so machine can understand it:\n",
    "\n",
    "1. creating vocabulary for our words and assign an unique number to each one\n",
    "\n",
    "    issues: numbers are random, they don't capture relationship between words\n",
    "2. one hot encodding: creating a vector for word existance\n",
    "\n",
    "    same issue as first option and computationally in-efficient\n",
    "3. word embedding: it will retrieve features from words then compare it , so it can say apple and bananna is similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b57f326-32e6-45c8-ae29-472f94023406",
   "metadata": {},
   "source": [
    "# word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feea684-10e0-4d20-b356-559490a78b19",
   "metadata": {},
   "source": [
    "convert words into features vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948a444-2a43-408f-b8ba-a6d1929ac2e1",
   "metadata": {},
   "source": [
    "we use different techniques like : TF-IDF , Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db773a5a-abc9-41fc-bb4d-4c716482369d",
   "metadata": {},
   "source": [
    "embeddings are not hand crafted , instead they are learned during neural network training\n",
    "\n",
    "techniques:\n",
    "1. using supervised learning\n",
    "2. using self-supervised learning\n",
    "   1. Word2vec\n",
    "   2. Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d414b750-3faa-474b-8233-57609630c1fe",
   "metadata": {},
   "source": [
    "# supervised learning\n",
    "\n",
    "take a NLP problem and try to solve it.in that pursuit as a side effect, you get word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e42f1-e8ba-4464-9feb-7fd976ef2703",
   "metadata": {},
   "source": [
    "we use padding to get fixed number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47a4569-b8bd-4785-b02c-bbd14a29a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1297967-1312-4194-96b6-ebe90778f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['nice food',\n",
    "        'amazing restaurant',\n",
    "        'too good',\n",
    "        'just loved it!',\n",
    "        'will go again',\n",
    "        'horrible food',\n",
    "        'never go there',\n",
    "        'poor service',\n",
    "        'poor quality',\n",
    "        'needs improvement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "541cd22b-35d5-4861-9027-32b0932d0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = np.array([1,1,1,1,1,0,0,0,0,0]) # first five are positive reviews and next five are negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c323af59-d4da-4da2-b854-91fc4362e7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 22]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot('amazing restaurant',30) # it will assign a number to words with 30 maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4d559d12-d017-4f3e-b3bb-733ed68ce574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[27, 12],\n",
       " [2, 21],\n",
       " [14, 2],\n",
       " [39, 4, 36],\n",
       " [7, 17, 29],\n",
       " [22, 12],\n",
       " [15, 17, 10],\n",
       " [3, 14],\n",
       " [3, 29],\n",
       " [27, 25]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 40\n",
    "\n",
    "encoded_reviews = [one_hot(a, vocab_size) for a in reviews]\n",
    "encoded_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79172519-68c2-413b-9de8-4dc3dfede2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 12,  0],\n",
       "       [ 2, 21,  0],\n",
       "       [14,  2,  0],\n",
       "       [39,  4, 36],\n",
       "       [ 7, 17, 29],\n",
       "       [22, 12,  0],\n",
       "       [15, 17, 10],\n",
       "       [ 3, 14,  0],\n",
       "       [ 3, 29,  0],\n",
       "       [27, 25,  0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need padding , some have less words than other reviews\n",
    "\n",
    "max_length = 3\n",
    "\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen= max_length, padding= 'post')\n",
    "padded_reviews  # now we have equal size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b72555ad-9677-414c-a0f3-652bfe32d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_vector_size = 4\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embeded_vector_size, input_length=max_length, name= 'embedding'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a314b05b-6269-4b54-801e-1c81e154d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = padded_reviews\n",
    "y = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "df4ec28c-872c-455f-a8d8-680642f752b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a74f1d85-2779-4ee6-90ca-e7c1945957a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 4)              160       \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "781bdd67-db2c-499a-918f-5f35eaf1a73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d2298096a0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a4bb96b-511e-4c0a-bf95-29839db62f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5664 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x, y)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "421ba7b7-6460-43f9-88f5-f20d6c007c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are more interested in word embedding and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3272be3a-b625-46f8-803e-cccbf5cfe3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6aa93b1e-3f3a-470b-8dc3-20dcb36c3f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f078c2ca-f82d-4f39-b12f-7f855822a284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08301078, -0.06225186,  0.11192101,  0.11618899], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "648aea61-fd97-4dd9-b6e1-a5b88c854a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12627634, -0.13584265,  0.08930933,  0.12957135], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
