{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b05d39-4ca0-4fae-a06f-631d14957a57",
   "metadata": {},
   "source": [
    "# popular image datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ca1b4-1bd7-40ae-9e9e-404a6f3bea35",
   "metadata": {},
   "source": [
    "labaling in big datasets milions of data is big problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fffcb77-5067-4591-9ea7-8f66f142aaff",
   "metadata": {},
   "source": [
    "process of assigning labels is called # annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd82b20-d631-4e40-b70e-f62dc822c960",
   "metadata": {},
   "source": [
    "COCO, google open image , imagenet  are 3 popular image datasets out there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089cdfd0-ec27-4dd4-90ec-1669f92361b3",
   "metadata": {},
   "source": [
    "# sliding window object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc788f4-914d-46f5-87d1-9c046817b9be",
   "metadata": {},
   "source": [
    "let's consider that we have a person and a dog in our image\n",
    "\n",
    "first step is to train a CNN to classify dog with cropped images of only dogs\n",
    "\n",
    "now we can use sliding window in our image, window size can be anything , the window will move and whenever it detects a dog (CNN will tell you there is dog or not) , the window is our box or loacation of the dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e7c80a-0c47-49a0-a4ba-dafbe216b745",
   "metadata": {},
   "source": [
    "window size: we should try and error, start with small window and increase the size step by step\n",
    "\n",
    "disadvantages to this method is: too much computation , bounding boxes might not be accurate\n",
    "\n",
    "--> sliding window was popular technique years ago , but now we use better techniques nowdays:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627ff3-67a3-46d0-b8eb-abc5a50b1147",
   "metadata": {},
   "source": [
    "R CNN technique : in this method we use reduced region for our detection\n",
    "\n",
    "fast R CNN : it is faster that R CNN\n",
    "\n",
    "faster R CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fe278-61da-46c0-83d5-61aae8dce865",
   "metadata": {},
   "source": [
    "# YOLO : (you only look once)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1afae6-bc3f-4160-8839-8c16d058543c",
   "metadata": {},
   "source": [
    "yolo is best technique for image detection byfar, it is standard way of object detection\n",
    "\n",
    "x_ train is our image and y_train is : object presence, center of the object location box, height of the box, length of the box, class indication\n",
    "\n",
    "then we train it on CNN , now with new image our model will tell us the class and location box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543abc9e-cbc8-4f1c-b221-8e39eccebe30",
   "metadata": {},
   "source": [
    "if we had multiple objects in our image:\n",
    "\n",
    "YOLO algorithm will divide image into grid cells (nxn) , for each of the grid cells it'll do the last step with little change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004b529-fd18-487d-852e-5add28fa0826",
   "metadata": {},
   "source": [
    "algorithm might detect multiple boxes for same object: we use IOU (intersection over union) for this matter\n",
    "\n",
    "اشتراک باکس ها را تقسیم بر اجتماع آن ها میکنیم:\n",
    "\n",
    "if value is 1 it mean they are completely overlapping\n",
    "\n",
    "value 0 means boxes have nothing in common and not overlapping.\n",
    "\n",
    "keep the max score box and discard other overlapping boxes  --> tenchnique called Non max suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae110903-5067-42ee-96ec-bed7bd655f10",
   "metadata": {},
   "source": [
    "when a grid cell contain n center of objects then we use anchor boxes and use vector of size n*7 instead of 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed22f41b-e378-406d-a23e-748c54ec9f35",
   "metadata": {},
   "source": [
    "# recurrent neural network RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287543b-ca96-43f2-9bbc-6121856cd06c",
   "metadata": {},
   "source": [
    "RNN mainly used for NLP(natural language process)\n",
    "\n",
    "uses: text recommendation , translation, named entity recognition(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28582947-607c-4991-93ae-b0ce2cc9424f",
   "metadata": {},
   "source": [
    "issues using ANN for sequence problems :\n",
    "\n",
    "1- no fixed size of neurons in a layer\n",
    "\n",
    "2- too much computation\n",
    "\n",
    "3- parameters are not shared : means sometime we couple of inputs have one output(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4345043e-69ab-40cb-bc9a-8674a7a66267",
   "metadata": {},
   "source": [
    "types of RNN:\n",
    "\n",
    "1- many to many: we have many inputs and many outputs\n",
    "\n",
    "2- many to one: we have many inputs and one output (sentiment analysis)\n",
    "\n",
    "3- one to many: we have one input and many outputs (music generator, or any generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931cc444-e76e-4ee6-bee7-918c995011a1",
   "metadata": {},
   "source": [
    "# vanishing and exploding gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d11261-137c-4649-be61-3077711afc28",
   "metadata": {},
   "source": [
    "vanishing gradient : as number of hidden layers grow, gradient becomes very small and weights will hardly change. this will hamper the learning process, and it is not good\n",
    "\n",
    "exploding gradient : when individual derivatives are large, the final derivate will also become huge and weights would change drastically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e18b57-6373-47c0-a759-7176aa14c23f",
   "metadata": {},
   "source": [
    "vanishing gradient problem is more prominent in very deep neural networks.\n",
    "\n",
    "solutions for these problems are: GRU and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465565d-e3a5-4af9-8b72-e8a05e800ecd",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c2f33d-9094-4d3b-9691-823f32c9e619",
   "metadata": {},
   "source": [
    "we are adding new weight for long term memory, we store keywords in long term memory\n",
    "\n",
    "forget gate: there is sigmoid activation function that makes our RNN forget last keywords\n",
    "\n",
    "input gate: there is sigmoid and tanh activation functions that will add new keyword into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc077371-8eb0-4b7f-ae04-787d19ddda2f",
   "metadata": {},
   "source": [
    "# GRU   gated recurrent unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57442c2-c72d-430b-bfb8-7ec51b440662",
   "metadata": {},
   "source": [
    "this version of RNN is newer than LSTM , so we are using it more frequently\n",
    "\n",
    "it combines long-term and short-term memory in hidden state\n",
    "\n",
    "it contains 2 gates:\n",
    "\n",
    "update gate: how much of past memory to retain using sigmoid activation function\n",
    "\n",
    "reset gate: how much of past memory to forget using sigmoid activation function\n",
    "\n",
    "and we add one hidden layer to combine update and reset into one state at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942d83b-8090-4393-a64b-00c421939326",
   "metadata": {},
   "source": [
    "difference between LSTM and GRU:\n",
    "\n",
    "1. LSTM: 3 gates: input , output, forget\n",
    "\n",
    "    GRU: 2 gates: reset, update\n",
    "\n",
    "2. LSTM: more accurate on longer sequence, less efficient\n",
    "\n",
    "    GRU: more efficient computation wise, getting more popular\n",
    "3. LSTM: invented 1995-1997\n",
    "\n",
    "    GRU: invented 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc41220f-283c-477a-8145-8ac16a287377",
   "metadata": {},
   "source": [
    "# bidirectional RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13faf827-df06-42a9-90d0-7e89d6922c8d",
   "metadata": {},
   "source": [
    "we use this for named entity problems\n",
    "\n",
    "in fact we use this kind of RNN when we are predicting word that its meaning is in next sentence, so we need to change direction, right to left\n",
    "\n",
    "adding new layer similar to RNN cells but the activation is right to left\n",
    "\n",
    "because of this layer now we influence of future words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
