{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e712fd9-a6a9-49dd-a3bf-7776d4a25bbb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " we use pre-trained model from google's tensorflow hub , and re-train it on new dataset, and we will add new layers to it for our new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c783f96-20dd-4b44-8451-a58338f325d3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Using pre-trained model saves lot of time and computational budget for new classification problem at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb1f7a-8c4a-4170-9b8c-3fc5895d0e78",
   "metadata": {},
   "source": [
    "google's model has 1.4 mil images and 1000 classes , we can use this for our image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cdf5e6-74ea-4610-aaa7-7bc59baa416b",
   "metadata": {},
   "source": [
    "we freeze all layers except the last one which is our activation layer , to use it on new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c024500-15cd-4222-a783-6f467b4b1dba",
   "metadata": {},
   "source": [
    "when we freeze these layers , the model weights won't change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39aa963-84c9-4d4b-aeec-1ce02c324721",
   "metadata": {},
   "source": [
    "when we perform training on new dataset weights won't change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c784e-1b14-49da-bcea-c4bbe54e527f",
   "metadata": {},
   "source": [
    "then we use softmax to classify it into n number of classes we want in our new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98e864-1dfa-4dbf-8844-aad0fe47e5b6",
   "metadata": {},
   "source": [
    "# we will use # mobilenet v2 model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308fb21b-5f1b-49f2-8e25-975d69d4fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import PIL.Image as image\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e963c8c1-e36e-44ce-ba3a-271870e25a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf66c34-4722-498d-b5de-b03f7b0bc4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (224,224)\n",
    "\n",
    "classifier = keras.Sequential([\n",
    "    hub.KerasLayer('https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4', input_shape= IMAGE_SHAPE+(3,)) # adding third dimension to image_shape\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507c0d50-284c-4d11-9cd4-ea0964d795f4",
   "metadata": {},
   "source": [
    "test the model if it works , whith new goldfish image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b112b2dc-75e0-4b66-9433-01c45168dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fish = image.open('datasets//transfer_learning//goldfish.jpg').resize(IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8998af87-7d63-406c-a01a-01bb76c86c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fish = np.array(gold_fish)/255.0  # convert image into array and scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95b48fe-062c-41a0-a434-9ca9b75ee698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_fish[np.newaxis, ...].shape  # adding index dimension , classifier accept data with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed8480c-67bf-4b7c-8a3d-9c5e67fee11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 563ms/step\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(gold_fish[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3853a605-4e2f-41a1-933a-5c2bf78d21f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.argmax() # it is index in our classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00f98a-4e82-43e6-9369-2f1871bf2555",
   "metadata": {},
   "source": [
    "we can use classes txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765de0f3-c0fd-4825-ada6-e2ec1e779845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background', 'tench', 'goldfish', 'great white shark', 'tiger shark']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels = []\n",
    "with open(\"datasets//transfer_learning//ImageNetLabels.txt\", \"r\") as f:\n",
    "    image_labels = f.read().splitlines() # it will split the line , each class written in one line\n",
    "image_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91834084-c6df-4aea-bad9-99a17d3daacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goldfish'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels[result.argmax()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d5bd3f-1260-406d-a10c-4e62124f7da5",
   "metadata": {},
   "source": [
    "# model predicted it correctly!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb5dfe2-8392-49fd-bc30-b88aa63e2a42",
   "metadata": {},
   "source": [
    "loading new dataset(flower photos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61887327-0349-4529-888b-a7cb072b6225",
   "metadata": {},
   "source": [
    "#### I used tensorflow offical tutorial: https://www.tensorflow.org/tutorials/images/classification as a reference and made bunch of changes to make it simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c21031-872d-41cd-a92f-ef611821c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \".//datasets//flower_photos//flower_photos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21828c5d-8741-4535-823e-ae1c40072e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('datasets/flower_photos/flower_photos')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "245c6a8d-7822-4aaf-b611-b33c0f453c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'daisy': list(data_dir.glob('daisy/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips': list(data_dir.glob('tulips/*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "421a03e5-8018-4b1b-aec5-f1577ca5edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d43148-c6c0-4f81-a33c-c9eee533fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for flower_name, images in flowers_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image)) # it will load image as array\n",
    "        resized_img = cv2.resize(img, (224,224))  # we will resize all images so all of them will be same size\n",
    "        x.append(resized_img)\n",
    "        y.append(flowers_labels_dict[flower_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60adf6b2-1ce0-461a-b7aa-9982683fa756",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bec7b27f-4e28-4904-a84d-b51bcc221028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "x_train, x_test, y_train, y_test = tts(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0d8e89d-548f-4e2d-a3e4-6ef5b84ff2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_train / 255\n",
    "x_test_scaled = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e934ab0-3c7b-4edc-932a-d73eb59fb5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 850ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([795, 880, 795], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = classifier.predict(np.array([x[0], x[1], x[2]]))\n",
    "predicted = np.argmax(predicted, axis=1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3adc04-2dea-4415-a2cc-ab4b136f91de",
   "metadata": {},
   "source": [
    "it will predict it based on labels we had in pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a8176cd-a0e0-48d8-8abb-61e6df75f599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'umbrella'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels[880]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef60a5-1879-4bca-9434-6491899501f7",
   "metadata": {},
   "source": [
    "# now let's modify the model for our new problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e408992-8496-46c7-96ca-ed138121c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_model = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4'\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable= False  # trainable False means freeze the layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb7018be-d3be-4ce6-8e03-aa92922c6bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 1001)              3540265   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,545,275\n",
      "Trainable params: 5,010\n",
      "Non-trainable params: 3,540,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    pretrained_model_without_top_layer,\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b170d3d-baf5-4988-9ef2-6744e97d3977",
   "metadata": {},
   "source": [
    "only last layer is our addition to the model and previous layers are from the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5cafa5b-7cf7-4f00-b709-c108ee049178",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18770a58-b397-43ad-86bc-83b94d17de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "92/92 [==============================] - 63s 630ms/step - loss: 0.8075 - acc: 0.7132\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 58s 633ms/step - loss: 0.3860 - acc: 0.8593\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 55s 599ms/step - loss: 0.3040 - acc: 0.8924\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 56s 606ms/step - loss: 0.2550 - acc: 0.9111\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 56s 608ms/step - loss: 0.2217 - acc: 0.9285\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 57s 618ms/step - loss: 0.1989 - acc: 0.9332\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 55s 601ms/step - loss: 0.1766 - acc: 0.9438\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 56s 608ms/step - loss: 0.1632 - acc: 0.9482\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 55s 598ms/step - loss: 0.1503 - acc: 0.9547\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 55s 596ms/step - loss: 0.1355 - acc: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5b4e92550>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_scaled, y_train, epochs= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70afae-ee9b-43b6-9fad-ed720f70af53",
   "metadata": {},
   "source": [
    "# here we can see that we have much better accuracy based on pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922c0774-1aa2-484b-90a7-63dc71af9478",
   "metadata": {},
   "source": [
    "here with less epochs we reach higher accuracy , which means we have to do less computation on our machine and with less time spent we reach higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2aa9e-0135-47d5-badb-f5ab09c3f06b",
   "metadata": {},
   "source": [
    "# it is all because of transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a57480c-2a4f-49c3-8770-56f9d4197bf6",
   "metadata": {},
   "source": [
    "this is why transfer learning is popular in computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd88b5e2-15f5-4bc2-b276-193c3a5d5a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 16s 622ms/step - loss: 0.4614 - acc: 0.8597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46137717366218567, 0.859673023223877]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078be5d-7f5e-4fb3-bfe1-0a028ceae4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
