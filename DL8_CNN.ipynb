{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71fa5661-80d1-4343-83c5-faca51764084",
   "metadata": {},
   "source": [
    "# CNN (convolutional neural network):\n",
    "to handle variety in digits we can use simple artificial neural network(ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b523e9e5-2aaa-41be-8a01-b6fa221404e8",
   "metadata": {},
   "source": [
    "# disadvantages of using ANN for image classificaton:\n",
    "1. too much computation\n",
    "2. treats local pixels same as pixels far apart\n",
    "3. sensitive to location of an object in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17d536-596f-4dfd-981d-5dcaf92ba85a",
   "metadata": {},
   "source": [
    "we use filters to make computer understand the features\n",
    "\n",
    "we put filter(pattern) on data and multiply it to the data and take average , with this we are creating feature map\n",
    "\n",
    "where ever we see number 1 or close to it, in feature map it means we have a pattern in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf27092-bbdf-4abf-a69d-4f91f2ccd7ac",
   "metadata": {},
   "source": [
    "it is important that where our pattern was activate in feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e34d9-229d-45c8-a3fc-11d58e45e6c6",
   "metadata": {},
   "source": [
    "filters are nothing but the feature detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6bf7c-7d05-421e-b184-d2d6606658ac",
   "metadata": {},
   "source": [
    "# location invariant: it can detect feature in any location of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bea2f5-1538-4516-a36d-f1deb71b1ffe",
   "metadata": {},
   "source": [
    "we can do filter over filter(feature map) over and over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e53a82-d630-4029-9e07-7f403077b0ac",
   "metadata": {},
   "source": [
    "after appling all filters we flatten the result and join them together then we create fully connected dense neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72e0ce-8808-4017-bdf0-3ae4178b837b",
   "metadata": {},
   "source": [
    "filter part is feature extraction part, and second part is classification part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197346b-b112-4452-9a01-ecb3d86dab13",
   "metadata": {},
   "source": [
    "relu helps with making the model nonlinear , and speeds up training, faster to compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9050c5-0418-4b23-9a70-879591312fb4",
   "metadata": {},
   "source": [
    "# pooling layers:\n",
    "pooling layer is used to reduce the size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34ad264-0ee9-47d3-b844-080da8f33036",
   "metadata": {},
   "source": [
    "max pooling: we take n*n part of feature map and put maximum value in the result(new feature map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fd177-5566-4b71-85cf-bead99f21f97",
   "metadata": {},
   "source": [
    "average pooling: same as maxpooling but we take average of the block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13ec558-757d-4484-b8b8-eb883af816f3",
   "metadata": {},
   "source": [
    "# max pooling is more common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b056799-af19-4c37-9266-9f99aa2ccca5",
   "metadata": {},
   "source": [
    "# benefits of pooling:\n",
    "1. reduces dimensions and computation\n",
    "2. reduce overfitting as there are less parameters\n",
    "3. model is tolerant towards variations,distortion (filtering noises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc9ccd-2fb2-477d-8b6b-6d624915a5d6",
   "metadata": {},
   "source": [
    "convolution + ReLU , then pooling , for each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f39ecd-2bdb-4da3-aa13-24066871284c",
   "metadata": {},
   "source": [
    "# benefits of convolution:\n",
    "1. connections sparsity reduces overfitting (means every node dosen't connect to every node like Dense layer)\n",
    "2. conv + pooling , gives location invariant feature detection\n",
    "3. parameter sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ed44f-50f0-4df0-a43f-e3142649db40",
   "metadata": {},
   "source": [
    "# CNN by itself dosen't take care of rotation and scale:\n",
    "1. we need to have rotated and scaled samples in training dataset\n",
    "2. if we don't have them then use data augmentation methods to generate new rotated/scaled samples from existing training samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b69146b-03c7-4b61-8084-be377fa72cc0",
   "metadata": {},
   "source": [
    "# we dont specify the filters , neural network will figure it out by itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f3f2a4-8dce-46dd-ad17-1f033da0e5e8",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
