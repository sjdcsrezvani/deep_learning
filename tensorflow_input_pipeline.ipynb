{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89c7584-6d6c-40d9-810f-a10f6fc3e334",
   "metadata": {},
   "source": [
    "## tensorflow pipelines\n",
    "\n",
    "when we are training a model ,our dataset is on hard disk, we have to convert it to number then process it on RAM\n",
    "\n",
    "it is fine when we have small dataset, but when we have millions of data and small storage on RAM , there is too much data for RAM to handle it\n",
    "\n",
    "streaming approach : we feed data as several batches into RAM with special data structure(tf.data.Dataset) and train our model for each batch\n",
    "\n",
    "if we want to clean our data we can use filter function\n",
    "\n",
    "we can use map function to scale image data by dividing it by 255\n",
    "\n",
    "then fit our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252d240-7634-49fa-97dd-f2870058c1a0",
   "metadata": {},
   "source": [
    "benefits of tf pipelines:\n",
    "1. handle huge datasets by streaming them from disk using batching\n",
    "2. apply transformations to make dataset ready for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4640fe64-bfd8-427a-8233-d6a4969cf5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80d795d3-7a46-4ba1-938a-40cea6ce87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21, 22, -108, 31, -1, 32, 34,31] # we have errors in our data(negative values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d72cb79-896a-4fba-9688-dc867f316fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers) # create tf dataset\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c989f6d7-7c6e-4d87-96c7-c3f95ef7dca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset:\n",
    "    print(sales.numpy()) # it is tensor object and we are converting it to numpy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e00a31e0-272d-424b-8a4c-e09ec46567b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator(): # we can do this to iterate it as numpy object\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77d99c57-28d8-41e8-a7d1-eb163c4a9413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.take(3).as_numpy_iterator(): # it will take first 3 elements\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "053ad80c-77c5-4562-a1a3-20e43964dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x: x>0) # filtering error data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "247dca40-8948-48a9-84a0-07d89553bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these numbers are in US dollars, and we want to convert it into IR tooman\n",
    "\n",
    "tf_dataset = tf_dataset.map(lambda x: x*60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6d5f353-8959-4370-837a-779dc1dd680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the elements of dataset\n",
    "\n",
    "tf_dataset = tf_dataset.shuffle(buffer_size=7) # for perfect shuffle buffer size have to be greater than dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86ea9063-3804-4de2-b99d-e2a13076c6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1920000 1860000]\n",
      "[1320000 2040000]\n",
      "[1260000 1860000]\n"
     ]
    }
   ],
   "source": [
    "# batching:\n",
    "\n",
    "for sales_batch in tf_dataset.batch(2).as_numpy_iterator(): # batch size is 2\n",
    "    print(sales_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6295f551-2e76-4848-af31-f34a86b46655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1260000 1860000]\n",
      "[1920000 2040000]\n",
      "[1320000 1860000]\n"
     ]
    }
   ],
   "source": [
    "# we can do all this functions in one single line:\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "\n",
    "tf_dataset = tf_dataset.filter(lambda x: x>0).map(lambda y: y*60000).shuffle(2).batch(2)\n",
    "\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e18c008-cf9d-4286-9208-f6b223949363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to our dataset directory and read the images\n",
    "images_ds = tf.data.Dataset.list_files('.\\\\datasets\\\\tensorflow_input_pipeline\\\\*\\\\*', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08c7ef3e-26e2-43b9-9e46-493e8624bfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'.\\\\datasets\\\\tensorflow_input_pipeline\\\\cat\\\\20 Reasons Why Cats Make the Best Pets....jpg'\n",
      "b'.\\\\datasets\\\\tensorflow_input_pipeline\\\\cat\\\\7 Foods Your Cat Can_t Eat.jpg'\n",
      "b'.\\\\datasets\\\\tensorflow_input_pipeline\\\\cat\\\\A cat appears to have caught the....jpg'\n"
     ]
    }
   ],
   "source": [
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "919d9e65-fcb5-4011-9fff-9dbb302dc6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'.\\\\datasets\\\\tensorflow_input_pipeline\\\\dog\\\\45 Best Large Dog Breeds - Top Big Dogs_yyth....jpg'\n",
      "b'.\\\\datasets\\\\tensorflow_input_pipeline\\\\dog\\\\why dogs understand our body language....jpg'\n",
      "b'.\\\\datasets\\\\tensorflow_input_pipeline\\\\dog\\\\Rottweiler Dog Breed Information....jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(200)\n",
    "\n",
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb08c3cf-9e79-4c93-be59-d711ed7cb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50096916-6399-4f32-b7c9-a7b45cb3d07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "baac05c5-27e9-4cc6-aaa7-bb4b62038e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(images_ds)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffd1fe4b-a280-4707-b197-6101cb8904a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = images_ds.take(train_size)\n",
    "\n",
    "test_ds = images_ds.skip(train_size)  # skip function will skip n number of samples and take the remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9343efe4-eeca-4328-94b9-d494c0770794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from image path we can take label\n",
    "import os\n",
    "def get_label(file_path):\n",
    "    return tf.strings.split(file_path, os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dd10924-17cc-4331-999b-a25f89ba3533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for label in train_ds.map(get_label):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44482db0-f9f2-4778-a2e3-ae8887e09cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns our x_train and y_train\n",
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path) # this will read our files\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [128,128])\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8223633-662d-4b4f-a0f9-da49561a4c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 24.         19.         15.       ]\n",
      "  [ 24.         19.         15.       ]\n",
      "  [ 21.863281   18.863281   13.863281 ]\n",
      "  ...\n",
      "  [143.92188   142.92188   148.92188  ]\n",
      "  [153.92847   151.08228   158.00537  ]\n",
      "  [104.69971    99.51221    97.07471  ]]\n",
      "\n",
      " [[ 22.076904   17.076904   13.076904 ]\n",
      "  [ 24.410156   19.410156   15.410156 ]\n",
      "  [ 18.07373    15.07373    10.07373  ]\n",
      "  ...\n",
      "  [144.7373    143.7373    149.7373   ]\n",
      "  [150.03638   154.59888   157.59888  ]\n",
      "  [123.66211   117.66211   120.03711  ]]\n",
      "\n",
      " [[ 22.1875     17.1875     13.1875   ]\n",
      "  [ 21.615479   16.615479   12.6154785]\n",
      "  [ 20.         17.         12.       ]\n",
      "  ...\n",
      "  [147.12085   146.12085   152.12085  ]\n",
      "  [147.23486   148.23486   152.23486  ]\n",
      "  [152.54517   150.54517   155.031    ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[138.17798   143.17798   146.17798  ]\n",
      "  [144.43701   149.1206    152.1206   ]\n",
      "  [163.23169   169.18091   172.8645   ]\n",
      "  ...\n",
      "  [128.80176   132.43457   137.11816  ]\n",
      "  [153.0188    150.84082   161.84082  ]\n",
      "  [100.593994  102.22681   107.85962  ]]\n",
      "\n",
      " [[178.29028   186.29028   188.29028  ]\n",
      "  [135.57666   136.57666   140.57666  ]\n",
      "  [154.99023   162.99023   165.99023  ]\n",
      "  ...\n",
      "  [150.86084   153.86084   158.86084  ]\n",
      "  [123.883545  124.87891   134.54712  ]\n",
      "  [156.92798   159.92798   164.92798  ]]\n",
      "\n",
      " [[155.90137   160.42212   168.4751   ]\n",
      "  [152.13867   152.00195   160.85352  ]\n",
      "  [139.37354   142.52197   147.3938   ]\n",
      "  ...\n",
      "  [136.94385   141.67041   145.80713  ]\n",
      "  [157.88354   162.0918    166.51758  ]\n",
      "  [138.22656   139.22656   144.08984  ]]], shape=(128, 128, 3), dtype=float32)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(\n",
      "[[[222.3125   233.3125   235.3125  ]\n",
      "  [230.       239.       238.      ]\n",
      "  [232.       241.       240.      ]\n",
      "  ...\n",
      "  [228.       239.       241.      ]\n",
      "  [230.       238.       241.      ]\n",
      "  [232.       240.       243.      ]]\n",
      "\n",
      " [[219.       230.       232.      ]\n",
      "  [230.       239.       238.      ]\n",
      "  [232.       241.       240.      ]\n",
      "  ...\n",
      "  [228.       239.       241.      ]\n",
      "  [230.       238.       241.      ]\n",
      "  [232.       240.       243.      ]]\n",
      "\n",
      " [[221.       232.       238.      ]\n",
      "  [221.72656  232.72656  234.72656 ]\n",
      "  [226.       237.       239.      ]\n",
      "  ...\n",
      "  [230.       238.       241.      ]\n",
      "  [230.       238.       241.      ]\n",
      "  [232.       240.       243.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[133.       135.        62.      ]\n",
      "  [119.71094  120.71094   52.710938]\n",
      "  [143.0625   139.0625    76.0625  ]\n",
      "  ...\n",
      "  [143.875    139.875     76.875   ]\n",
      "  [142.4375   142.4375    82.4375  ]\n",
      "  [141.125    136.4375    84.      ]]\n",
      "\n",
      " [[133.3125   132.3125    68.1875  ]\n",
      "  [111.33594  109.33594   48.335938]\n",
      "  [142.14844  138.08594   74.08594 ]\n",
      "  ...\n",
      "  [139.       135.9375    85.125   ]\n",
      "  [145.1875   132.875     83.125   ]\n",
      "  [132.3125   134.625     66.125   ]]\n",
      "\n",
      " [[127.875    135.53906   68.375   ]\n",
      "  [118.625    124.25      68.875   ]\n",
      "  [130.19531  131.82031   74.13281 ]\n",
      "  ...\n",
      "  [133.375    141.3125    70.375   ]\n",
      "  [128.4375   145.9375    60.75    ]\n",
      "  [122.359375 150.125     59.875   ]]], shape=(128, 128, 3), dtype=float32)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "tf.Tensor(\n",
      "[[[ 71.078125 119.078125 193.07812 ]\n",
      "  [ 71.       119.       193.      ]\n",
      "  [ 72.16406  120.16406  194.16406 ]\n",
      "  ...\n",
      "  [ 72.22937  120.22937  194.22937 ]\n",
      "  [ 73.       121.       195.      ]\n",
      "  [ 72.02869  120.02869  194.02869 ]]\n",
      "\n",
      " [[ 72.765625 120.765625 194.76562 ]\n",
      "  [ 71.0238   119.0238   193.0238  ]\n",
      "  [ 72.359985 120.359985 194.35999 ]\n",
      "  ...\n",
      "  [ 71.       119.       193.      ]\n",
      "  [ 73.       121.       195.      ]\n",
      "  [ 70.234375 118.234375 192.23438 ]]\n",
      "\n",
      " [[ 73.       121.       195.      ]\n",
      "  [ 73.35095  121.35095  195.35095 ]\n",
      "  [ 73.       121.       195.      ]\n",
      "  ...\n",
      "  [ 71.       119.       193.      ]\n",
      "  [ 73.       121.       195.      ]\n",
      "  [ 72.609375 120.609375 194.60938 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[163.531    170.531     91.759766]\n",
      "  [161.01501  175.09253   93.670654]\n",
      "  [ 97.33179  109.15991   60.909912]\n",
      "  ...\n",
      "  [130.3357   150.09973   73.16223 ]\n",
      "  [139.37988  158.37146   86.58118 ]\n",
      "  [132.2666   154.84753   81.19849 ]]\n",
      "\n",
      " [[177.79456  188.3258   115.95862 ]\n",
      "  [101.04651  127.734375  56.086304]\n",
      "  [129.89478  143.7019    69.795044]\n",
      "  ...\n",
      "  [142.78369  162.72119   83.48682 ]\n",
      "  [141.94714  156.51636   84.54016 ]\n",
      "  [141.75171  163.62695   88.86133 ]]\n",
      "\n",
      " [[171.49438  177.49438  106.66113 ]\n",
      "  [109.82214  137.02527   56.267212]\n",
      "  [122.75159  142.11316   60.243774]\n",
      "  ...\n",
      "  [132.9303   154.69592   71.77405 ]\n",
      "  [186.06274  193.74194  112.94531 ]\n",
      "  [145.08337  155.93506   78.812744]]], shape=(128, 128, 3), dtype=float32)\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for img, label in train_ds.map(process_image).take(3):\n",
    "    print(img)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a18dfa50-95b3-4ef5-86d6-4ebb1f95770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to scale x_train\n",
    "\n",
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4a9152b-d6bb-4e08-bcc0-a52dad8dca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(process_image)\n",
    "test_ds = test_ds.map(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d4150b5-b693-4920-8bdd-35e86b73b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(scale)\n",
    "test_ds = test_ds.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9440eacb-7547-483c-a22c-5d2a251d3ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>image:  [0.3987501 0.5242403 0.6222795]\n",
      ">>>label:  b'cat'\n",
      ">>>image:  [0.63529414 0.6392157  0.6156863 ]\n",
      ">>>label:  b'dog'\n",
      ">>>image:  [0.3577304 0.6239124 0.4327638]\n",
      ">>>label:  b'dog'\n",
      ">>>image:  [0.8718137  0.91495097 0.9227941 ]\n",
      ">>>label:  b'dog'\n",
      ">>>image:  [0.03924632 0.07846201 0.04316789]\n",
      ">>>label:  b'cat'\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(5):\n",
    "    print(\">>>image: \",image.numpy()[0][0])\n",
    "    print(\">>>label: \",label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f45aac9-ab17-4726-8af4-43992985b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can merge all functions into one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
